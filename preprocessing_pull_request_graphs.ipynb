{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Script \n",
    "In this script we calculate the feature vectors for all graphs that have before been created from \n",
    "projects' data in the ghtorrent data base (see script scrape_pr_graphs_from_ghtorrent.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load networks from pickle file\n",
    "def pickleLoader(pklFile):\n",
    "    try:\n",
    "        while True:\n",
    "            yield nx.read_gpickle(pklFile)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_eps = 10**(-10)\n",
    "\n",
    "def get_features(A):\n",
    "    \"\"\"Feature grabber for DiNetSimile algorithm. Features used are\n",
    "\n",
    "        1. In-Degree of node\n",
    "        2. Out-Degree of node\n",
    "        3. Clustering coefficient of node\n",
    "        4. Average clustering coefficient of predecessors of node\n",
    "        5. Average clustering coefficient of successors of node\n",
    "        6. Average number of successors of succesors of node\n",
    "        7. Average number of successors of predecessors of node\n",
    "        8. Average number of predecessors of succesors of node\n",
    "        9. Average number of predecessors of predecessors of node\n",
    "        10. Number of edges in successor egonet of node\n",
    "        11. Number of edges in predecessor egonet of node\n",
    "        12. reciprocity of in/out edges of node\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    A : NumPy matrix\n",
    "        Adjacency matrix of graph in question. Preferably a SciPy sparse matrix\n",
    "        for large graphs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    feature_mat : NumPy array\n",
    "        An n by 12 array of features, where n = A.shape[0]\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        G = nx.from_scipy_sparse_matrix(A, create_using=nx.DiGraph())\n",
    "    except AttributeError:\n",
    "        G = nx.from_numpy_matrix(A, create_using=nx.DiGraph())       \n",
    "    n = len(G)\n",
    "\n",
    "    #number of in/out neighbors\n",
    "    neighbors_suc = [list(set(G.successors(i))-{i}) for i in range(n)]\n",
    "    neighbors_pre = [list(set(G.predecessors(i))-{i}) for i in range(n)]\n",
    "    d_vec_out = np.array([len(suc) for suc in neighbors_suc])\n",
    "    d_vec_in = np.array([len(pre) for pre in neighbors_pre])\n",
    "\n",
    "    # average in/out degree of neighbors (successors) (0 if node is isolated)\n",
    "    neighbor_suc_deg_in = [d_vec_in[neighbors_suc[i]].sum()/d_vec_out[i]\n",
    "                    if d_vec_out[i]>_eps else 0 for i in range(n)]\n",
    "    neighbor_suc_deg_out = [d_vec_out[neighbors_suc[i]].sum()/d_vec_out[i]\n",
    "                    if d_vec_out[i]>_eps else 0 for i in range(n)]\n",
    "\n",
    "    # average in/out degree of neighbors (predecessors) (0 if node is isolated)\n",
    "    neighbor_pre_deg_in = [d_vec_in[neighbors_pre[i]].sum()/d_vec_in[i]\n",
    "                    if d_vec_in[i]>_eps else 0 for i in range(n)]\n",
    "    neighbor_pre_deg_out = [d_vec_out[neighbors_pre[i]].sum()/d_vec_in[i]\n",
    "                    if d_vec_in[i]>_eps else 0 for i in range(n)]\n",
    "\n",
    "    #clustering coefficient for all nodes\n",
    "    clust_vec = np.array(list(nx.clustering(G).values()))\n",
    "\n",
    "    #average clustering coefficient for predecessors and successors\n",
    "    neighbor_clust_pre = [clust_vec[neighbors_pre[i]].sum()/d_vec_in[i] \n",
    "                      if d_vec_in[i]>_eps else 0 for i in range(n)]\n",
    "    neighbor_clust_suc = [clust_vec[neighbors_suc[i]].sum()/d_vec_out[i] \n",
    "                      if d_vec_out[i]>_eps else 0 for i in range(n)]\n",
    "\n",
    "\n",
    "    # egonets predecessors and successors\n",
    "    egonets_suc = [nx.ego_graph(G,i) for i in range(n)]\n",
    "    egonets_pre = [nx.ego_graph(G.reverse(),i) for i in range(n)]\n",
    "\n",
    "    # number of edges in egonet\n",
    "    ego_size_suc = [D.size() for D in egonets_suc]\n",
    "    ego_size_pre = [D.size() for D in egonets_pre]\n",
    "\n",
    "\n",
    "    #reciprocity - selfloops are ignored and isolate notes are given reciprocity zeroo\n",
    "    G.remove_edges_from(G.selfloop_edges())\n",
    "    recipro_dict=nx.algorithms.reciprocity(G,  nodes=[node for node in G])\n",
    "    recipro=[]\n",
    "    for k,v in recipro_dict.items():\n",
    "        if v==None:\n",
    "            recipro.append(0.0)\n",
    "        else:\n",
    "            recipro.append(v)\n",
    "\n",
    "\n",
    "    # use mat.T so that each node is a row (standard format)\n",
    "    feature_mat = np.array([d_vec_in, d_vec_out, clust_vec, neighbor_suc_deg_in, neighbor_suc_deg_out,\n",
    "                            neighbor_pre_deg_in, neighbor_pre_deg_out, neighbor_clust_pre, neighbor_clust_suc,\n",
    "                            ego_size_pre, ego_size_suc, recipro]).T \n",
    "\n",
    "    return feature_mat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_features(feature_mat,row_var=False,as_matrix=False):\n",
    "    \"\"\"Returns column-wise descriptive statistics of a feature matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_mat : NumPy array\n",
    "        Matrix on which statistics are to be calculated. Assumed to be formatted\n",
    "        so each row is an observation (a node, in the case of NetSimile).\n",
    "\n",
    "    row_var : Boolean, optional (default=False)\n",
    "        If true, then each variable has it's own row, and statistics are\n",
    "        computed along rows rather than columns.\n",
    "\n",
    "    as_matrix : Boolean, optional (default=False)\n",
    "        If true, then description is returned as matrix. Otherwise, it is\n",
    "        flattened into a vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    description : NumPy array\n",
    "        Descriptive statistics of feature_mat\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    axis = int(row_var) \n",
    "    description = np.array([feature_mat.mean(axis=axis),\n",
    "                            np.median(feature_mat,axis=axis),\n",
    "                            np.std(feature_mat,axis=axis),\n",
    "                            stats.skew(feature_mat,axis=axis),\n",
    "                            stats.kurtosis(feature_mat,axis=axis)])\n",
    "    if not as_matrix:\n",
    "        description = description.flatten()\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle_graphs_all_randSample_noFork_6months_chunk0.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk1.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk10.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk11.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk12.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk13.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk14.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk15.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk16.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk17.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk18.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk19.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk2.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk20.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk21.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk22.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk23.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk24.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk25.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk26.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk27.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk28.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk29.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk3.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk30.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk31.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk32.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk33.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk34.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk35.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk36.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk37.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk38.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk39.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk4.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk40.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk41.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk42.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk43.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk44.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk45.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk46.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk47.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk48.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk49.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk5.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk6.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk7.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk8.gpickle\n",
      "pickle_graphs_all_randSample_noFork_6months_chunk9.gpickle\n"
     ]
    }
   ],
   "source": [
    "#directory where graph data of all the projects lies.\n",
    "directory=\"path/to/folder\"\n",
    "# directory to \n",
    "newdir=\"path/to/folder/featurevecs/\"\n",
    "allfiles=listdir(directory)\n",
    "filesrefined=[f for f in allfiles if f.startswith(\"pickle_graphs_all_randSample_noFork_6months\")]\n",
    "\n",
    "try:\n",
    "    already_preprocessed_filelist=pickle.load(open(newdir+\"already_preprocessed_weighted_filelist.p\", \"rb\"))\n",
    "except:\n",
    "    already_preprocessed_filelist=[]\n",
    "    pass\n",
    "\n",
    "for file in filesrefined:\n",
    "    if file not in already_preprocessed_filelist:\n",
    "        print(file)\n",
    "        \n",
    "        networkl=[]\n",
    "        with open(directory + file, \"rb\") as f:\n",
    "            for graph in pickleLoader(f):\n",
    "                networkl.append(graph)\n",
    "                \n",
    "        feature_vecs=dict({})\n",
    "        for i,net in enumerate(networkl):\n",
    "            try:\n",
    "                feat = get_features(nx.adjacency_matrix(net)) \n",
    "                aggr_feat= aggregate_features(feat)\n",
    "                feature_vecs[net.graph[\"id\"]]=aggr_feat\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        feature_vecs_3to7={}\n",
    "        feature_vecs_8to20={}\n",
    "        feature_vecs_21to50={}\n",
    "        feature_vecs_over50={}\n",
    "        for net in networkl:\n",
    "            try:\n",
    "                leng=len(net.nodes)\n",
    "                key=net.graph[\"id\"]\n",
    "                if leng > 2 and leng < 8:\n",
    "                    feature_vecs_3to7[key]=feature_vecs[key]\n",
    "                elif leng >= 8 and leng < 21:\n",
    "                    feature_vecs_8to20[key]=feature_vecs[key]\n",
    "                elif leng >= 21 and leng < 51:\n",
    "                    feature_vecs_21to50[key]=feature_vecs[key]\n",
    "                elif leng>=50:\n",
    "                    feature_vecs_over50[key]=feature_vecs[key]\n",
    "            except:\n",
    "                pass\n",
    "        pickle.dump(feature_vecs_3to7,open(newdir + \"feature_vecs_3to7.p\", \"ab\"))\n",
    "        pickle.dump(feature_vecs_8to20,open(newdir + \"feature_vecs_8to20.p\", \"ab\"))\n",
    "        pickle.dump(feature_vecs_21to50,open(newdir + \"feature_vecs_21to50.p\", \"ab\"))\n",
    "        pickle.dump(feature_vecs_over50,open(newdir + \"feature_vecs_over50.p\", \"ab\"))\n",
    "        already_preprocessed_filelist.append(file)\n",
    "        \n",
    "        #free memory\n",
    "        del networkl\n",
    "        del feature_vecs_3to7\n",
    "        del feature_vecs_8to20\n",
    "        del feature_vecs_21to50\n",
    "        del feature_vecs_over50\n",
    "        del feature_vecs\n",
    "        \n",
    "pickle.dump(already_preprocessed_filelist,open(newdir+\"already_preprocessed_weighted_filelist.p\", \"wb\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
